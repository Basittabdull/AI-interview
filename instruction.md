nstruction File: TalentFlow Real-Time AI Interview Module
1. Project Overview
The goal of this project is to build a real-time, conversational AI interview module. This will simulate a live interview between a job candidate and an AI interviewer named "Eva." The system will handle real-time audio processing, natural language understanding, and dynamic response generation to create a seamless and interactive experience.

The primary user interface for this module is provided in Frontend/Module4/Module4.html.

2. Core Features
Frontend (User-Facing Interface)
Real-Time Audio & Video: Capture the candidate's audio and video streams directly in the browser.

Interactive AI Avatar: Display a visual representation of "Eva" that changes state to indicate listening, processing, and speaking.

Live Transcription: Show a real-time text transcript of the candidate's spoken responses.

Hardware Check: Before the interview, verify that the user's camera and microphone are functional.

Integrated Coding Environment: Include a tab with a simple code editor for a live coding challenge that can be activated during the interview.

Backend (AI and Communication Logic)
Real-Time Communication: Utilize a WebSocket server to maintain a persistent, low-latency connection between the frontend and backend.

Speech-to-Text (STT): Implement a service to instantly transcribe the incoming audio stream from the candidate into text.

Large Language Model (LLM) Integration: Connect to a powerful LLM (e.g., Gemini) to:

Understand the candidate's transcribed answers.

Generate relevant, context-aware follow-up questions in real-time.

Drive the conversation flow from greetings to technical questions to a conclusion.

Text-to-Speech (TTS): Convert the text responses generated by the LLM into natural-sounding audio to be played back to the candidate.

3. The Real-Time Interview Flow
The entire interview process will be a seamless, real-time loop to ensure a natural conversational experience:

Eva Asks a Question: The backend sends an audio stream to the frontend, and "Eva" asks a question.

Candidate Responds: The candidate speaks their answer. Their audio is captured by the browser and streamed to the backend via the WebSocket connection.

Backend Transcribes: The Speech-to-Text service processes the audio and converts it into a text transcript instantly.

LLM Generates Reply: The transcript is sent to the LLM, which analyzes the answer and immediately formulates the next question or comment.

Backend Synthesizes Speech: The LLM's text response is converted into an audio stream by the Text-to-Speech service.

Loop Continues: The new audio stream is sent back to the frontend, and Eva asks the next question, continuing the conversation without noticeable delay.
